---
title: "The r3PG R package"
author: "Volodymyr Trotsiuk, Florian Hartig, David I. Forrester"
date: "`r Sys.Date()`"
abstract: "This vignette provides an overview of the r3PG R package functions and options. We provide an working exampleswhich (i) demonstrates the basic functionality and use of the package, (ii) performs a sensitivity analysis and a Bayesian calibration of the model, and (iii) uses the calibrated model to simulate spatial patterns of forest growth across Switzerland.  \n \n \n"
output: 
  rmarkdown::html_vignette:
    toc: true
    toc_depth: 3
vignette: >
  %\VignetteIndexEntry{Vignette for the r3PG R package}
  %\VignetteEngine{knitr::rmarkdown}
  \usepackage[utf8](inputenc)
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  warning=FALSE, 
  message = FALSE,
  cache = F,
  collapse = TRUE,
  comment = "#>"
)

library(knitr)
```


## Prerequisite 
In order to reproduce all the examples, please make sure that the below listed r packages are installed.

```{r libraries}
library(r3PG)

library(dplyr)
library(tidyr)
library(purrr)

library(multidplyr)

library(ggplot2)

library(BayesianTools)
library(sensitivity)
```


We will be using freely available forest growth data from the [PROFOUND database](https://doi.org/10.5194/essd-2019-220) for the analysis. In order to use them directly with `r3PG` we have prepared the data in required format. We also saved the meteorological data used for simulations on Swiss scale. The interpolation of the meteorological data used to force 3-PG model was done by the Landscape Dynamics group (WSL, Switzerland) using data from MeteoSwiss stations (Swiss Federal Office of Meteorology and Climatology) by employing the DAYMET method (Thornton et al., 1997). 

```{r data}
load('vignette_data/solling.rda')
load('vignette_data/grid_input.rda')
```

## Single model runs

To demonstrate the basic functionality of the `r3PG` R package, we will perform a simple simulations with the `3-PGmix` model. The central function to run `3-PG` from within R is `run_3PG`. When called, the function will:

- check the model input for the consistency in structure
- replace the default parameters if new ones are provided
- run and return the simulated output from the model.

Before using `run_3PG` it is required that the user prepares the input data as described in the package description. In particular, it is important to prepare information about site conditions, species initial conditions, climate data, and parameters (if they need to be modified). In the  example presented, we run a simulation for the mixed *Fagus sylvatica* and *Pinus sylvestris* stands (Forrester et al., 2017). The input data are provided in the package. The output of the `run_3PG` function can be either a list with 2 objects: *sp_info* - information about species names and simulation start; *sim* - actual simulation of the model or a long format dataframe. In first case, the *sim* object is a 4-dimentional array where each row corresponds to one month of simulations. The second dimension corresponds to species, where each column represents one species. The third dimension corresponds to variable groups and the variables themselves To get the information about output variables and their group, please look at `data('output_info')`. 

```{r run_model}
out <- run_3PG(
  siteInputs = site_eum, 
  speciesInputs = species_eum, 
  forcingInputs = climate_eum, 
  managementInputs = NULL,
  parameterInputs = parameters_eum, 
  biasInputs = bias_eum,
  settings = list(light_model = 2, transp_model = 2, phys_model = 2, 
    correct_bias = 1, calculate_d13c = 0),
  df_out = FALSE)

str(out)
```

For easy use and exploration, we convert the default model output into the long format using function `tranf_out`. This function tranforms all the data into long format, where each row corresponds to one observational value, assigned to data, species, and variable names.
```{r tranform}
out_long <- transf_out( out )

head( out_long )
```


To visualize the output we select six main variables: *basal area*, *dbh*, *height*, *stem biomass*, *foliage biomass*, and *root biomass*. For visualization we are using a `ggplot` function, which allows us to visualize all the outputs side-by-side. The simulation indicates that *P. sylvestris* retains its dominant position within the canopy but that *F. sylvatica* is catching up, in terms of height and foliage mass. 
```{r morris_figure, fig.height=4.5, fig.width=6.6}
i_var <- c('stems_n',  'dbh', 'height', 'biom_stem', 'biom_root', 'biom_foliage')
i_lab <- c('Stem density', 'DBH', 'Height', 'Stem biomass', 'Root biomass', 'Foliage biomass')

out_long %>%
  filter(variable %in% i_var) %>%
  mutate(variable = factor(variable, levels = i_var)) %>%
  ggplot( aes(date, value))+
  geom_line( aes(color = species), size = 0.5)+
  facet_wrap( ~ variable, scales = 'free_y', ncol = 3, 
    labeller = labeller(variable = setNames(i_lab, i_var) )) +
  scale_color_brewer('', palette = 'Dark2') +
  theme_classic()+
  theme(legend.position="bottom")+
  xlab("Calendar date") + ylab('Value')
```


## Sensitivity analysis and Bayesian calibration

As a second example, we will first performed a `Morris` screening and then perform the `Bayesian calibration` of 3-PGpjs model. We will use the `Solling` forest flux site located in Germany at an elevation of 508 m.a.s.l., and dominated by *Pice abies*. We obtained data for this site via the [PROFOUND database](https://doi.org/10.5194/essd-2019-220) for evaluating vegetation models and simulating climate impacts on forests (Reyer et al., 2019). There are almost 50 years of records for various stand and flux variables for `Solling` site.

### Likelihood function

To perform a `morris` sensitivity analysis and `Bayesian calibration` we construct the log Likelihood function. The log Likelihood function was calculated using normal error assumptions for six variables that describe stand stocks and characteristics: *basal area*, *dbh*, *height*, *stem biomass*, *foliage biomass*, and *root biomass*. To calculate the stand-level stocks, we applied the biomass equations developed for European forests following Forrester et al. (2017) for each measured tree, and summed it up to the stand level in Mg dry matter $ha^{-1}$. We will be using a faster function for running the 3-PG model - `f_3PG`. This function assumes that all input data are correct and avoids checking the input data, in contrast to the default `run_3PG`. Before using `f_3PG` make sure that you provide data in the required form.

```{r funs}
r3pg_ll <- function( pars ){
  #' @param pars a vector of parameters for the calibration, including errors 

  # replace the default values for the selected parameters
  pars <- setNames(pars, par_cal_names)
  
  par_def[which( names(par_def) %in% par_cal_names)] <- pars[-grep('err', par_cal_names)]
  err_def <- pars[grep('err', par_cal_names)]
  
  # simulate the model
  sim.df <- f_3PG(
    siteInputs = site_solling, 
    speciesInputs = species_solling,
    forcingInputs = climate_solling,
    managementInputs = thinn_solling,
    parameterInputs = par_def, 
    biasInputs = matrix(NA_real_, nrow = 30, ncol = 2 ),
    n_sp = 1L, n_m = 552L, n_man = 14L, t_t = 14L, 
    settings = c(1L, 1L, 1L, 0L, 0L), sp_names = 'piab', df_out = FALSE )$sim
  
  sim.df <- cbind(sim.df[,,2,c(3,5,6)], sim.df[,,4,c(1,2,3)])
  
  # calculate the log likelihood
  logpost <- sapply(1:6, function(i) {
    likelihoodIidNormal( sim.df[,i], observ_solling_mat[,i], err_def[i] ) 
  }) %>% sum(.)
  
  if(is.nan(logpost) | is.na(logpost) | logpost == 0 ){logpost <- -Inf}
  
  return( logpost )
}
```

### Priors and default

For Morris sensitivity analysis and Bayesian callibration we define the parameters range, for which we will evaluate first the sensitivity and later perform calibration. In addition, we specified error parameters for each of those observational data. 
```{r def_input}
# default parameters
par_def <- setNames(param_solling$default, param_solling$param_name)
err_def <- setNames(error_solling$default, error_solling$param_name)

# parameters for callibration and their ranges
param_morris.df <- bind_rows(param_solling, error_solling) %>% filter(!is.na(min))
par_cal_names <- param_morris.df$param_name
par_cal_min <- param_morris.df$min
par_cal_max <- param_morris.df$max
par_cal_best <- param_morris.df$default

r3pg_ll( par_cal_best)
```

### Morris sensitivity

With below specified settings we will run a total of 30500 model runs (N (length(factors)+1)) and visualize the results The morris sensitivity run will take approximately 4 minutes on the working computer.

```{r morris, eval = F}
morris_setup <- createBayesianSetup(
  likelihood = r3pg_ll, 
  prior = createUniformPrior(par_cal_min, par_cal_max, par_cal_best), 
  names = par_cal_names)

set.seed(432)
morrisOut <- morris(
  model = morris_setup$posterior$density,
  factors = par_cal_names, 
  r = 500, 
  design = list(type = "oat", levels = 20, grid.jump = 3), 
  binf = par_cal_min, 
  bsup = par_cal_max, 
  scale = TRUE)

# summarise the moris output
morrisOut.df <- data.frame(
  parameter = par_cal_names,
  mu.star = apply(abs(morrisOut$ee), 2, mean, na.rm = T),
  sigma = apply(morrisOut$ee, 2, sd, na.rm = T)
) %>%
  arrange( mu.star )
```
```{r morris_load, include=F}
load('vignette_data/morris.rda')
```

We visualize the results of `morris` analysis by listing all the parameters and error parametsr. A high $\mu^{*}$ indicates a factor with an important overall influence on model output; a high $\alpha$ indicates either a factor interacting with other factors or a factor whose effects are non-linear. 

```{r morris_vis, fig.height=4, fig.width=6.6, }
morrisOut.df %>%
  gather(variable, value, -parameter) %>%
  ggplot(aes(reorder(parameter, value), value, fill = variable), color = NA)+
  geom_bar(position = position_dodge(), stat = 'identity') +
  scale_fill_brewer("", labels = c('mu.star' = expression(mu * "*"), 'sigma' = expression(sigma)), palette="Dark2") +
  theme_classic() +
  theme(
    axis.text = element_text(size = 6),
    axis.text.x = element_text(angle=90, hjust=1, vjust = 0.5),
    axis.title = element_blank(),
    legend.position = c(0.05 ,0.95),legend.justification = c(0.05,0.95)
  )
```

### Bayesian calibration

We will run the Bayesian calibration for the 20 most sensitive parameters defined by the `morris` sensitivity plus six errors parrameters for each of the observational variable. We will run 3 parallel chains, each on the separate computer node for 4e+06 iterations. This can easily be done on a computer server, and takes approximately 21 hours. 

```{r mcmc, eval=F}
# which parameters to calibrate
par_select <- morrisOut.df$parameter %>% .[-grep('err', .)] %>% tail(., 20) %>% as.character()
par_id <- which(par_cal_names %in% c(par_select,  error_solling$param_name) )

par_cal_names <- par_cal_names[par_id]
par_cal_min <- par_cal_min[par_id]
par_cal_max <- par_cal_max[par_id]
par_cal_best <- par_cal_best[par_id]
 
mcmc_setup <- createBayesianSetup(
  likelihood = r3pg_ll, 
  prior = createUniformPrior(par_cal_min, par_cal_max, par_cal_best), 
  names = par_cal_names)
  
mcmc_out <- runMCMC(
  bayesianSetup = mcmc_setup, 
  sampler = "DEzs",
  settings = list(iterations = 4e+06, nrChains = 3))
```
```{r mcmc_load, include=F}
load('vignette_data/mcmc.rda')
```

As the first step, we would look at the Gelman-Rubin diagnostic. The convergence can be accepted as the multivariate potential scale reduction factor was $\le$ 1.1. 

```{r mcmc_gelamn}
gelmanDiagnostics( mcmc_out )
```

To evaluate the model performance, we draw ~500 samples from the mcmc object and run model simulations for each of the parameter combinations to understand model uncertainties.
```{r mcmc_draw}
param.draw <- getSample(mcmc_out, numSamples = 500, coda = F, whichParameters = 1:20) %>%
  as.data.frame() %>%
  mutate(mcmc_id = 1:n()) %>%
  nest_legacy(-mcmc_id, .key = 'pars')   %>%
  mutate( pars = map(pars, unlist))
```

We then simulate the forest growth using the defaults and the drawn parameters combination. Afterwards, we visualize the posteriori predition range by drawing the $5^{th}$ and $95^{th}$ range of predictions. The callibrated model simulate well the observational data.
```{r sim_post, fig.height=4.5, fig.width=6.6}
sim_r3PG <- function( pars ){
  #' @description function to simulate the model for a given parameter combinations
  #' @param pars a named vector of parameters, excluding error parameters

  # replace the default values for the selected parameters
  par_def[which( names(par_def) %in% names(pars))] = pars
  
  sim.df <- f_3PG(
    siteInputs = site_solling, 
    speciesInputs = species_solling,
    forcingInputs = climate_solling,
    managementInputs = thinn_solling,
    parameterInputs = par_def, 
    biasInputs = matrix(NA_real_, nrow = 30, ncol = 2 ),
    n_sp = 1L, n_m = 552L, n_man = 14L, t_t = 14L, 
    settings = c(1L, 1L, 1L, 0L, 0L), sp_names = 'piab', df_out = TRUE )
  
  return( sim.df )
}

# default run
def_run.df <- sim_r3PG( setNames(par_cal_best, par_cal_names) ) %>%
  select(date, variable, value) %>%
  mutate(run = 'default')

# calibrated run
post_run.df <-  param.draw %>%
  mutate( sim = map( pars, sim_r3PG)) %>%
  select(mcmc_id, sim) %>%
  unnest_legacy() %>%
  group_by(date, variable) %>%
  summarise(
    q05 = quantile(value, 0.05, na.rm = T),
    q95 = quantile(value, 0.95, na.rm = T),
    value = quantile(value, 0.5, na.rm = T)) %>%
  ungroup() %>%
  mutate(run = 'calibrated')

sim.df <- bind_rows( def_run.df, post_run.df)

# Visualize
i_var <- c('basal_area',  'dbh', 'height', 'biom_stem', 'biom_root', 'biom_foliage')
i_lab <- c('Stem density', 'DBH', 'Height', 'Stem biomass', 'Root biomass', 'Foliage biomass')

observ_solling.df <- observ_solling %>%
  gather(variable, value, -date) %>%
  filter(variable %in% i_var) %>%
  filter(!is.na(value)) %>%
  mutate(variable = factor(variable, levels = i_var))

sim.df %>%
  filter(variable %in% i_var) %>%
  mutate(variable = factor(variable, levels = i_var)) %>%
  ggplot(aes(date, value))+
  geom_ribbon(aes(ymin = q05, ymax = q95, fill = run), alpha = 0.5)+
  geom_line( aes(color = run), size = 0.2)+
  geom_point( data = observ_solling.df, color = 'grey10', size = 0.1) +
  facet_wrap( ~ variable, scales = 'free_y', nrow = 2, labeller = labeller(variable = setNames(i_lab, i_var) )) +
  scale_color_manual('', values = c('calibrated' = '#1b9e77', 'default' = '#d95f02')) +
  scale_fill_manual('', values = c('calibrated' = '#1b9e77', 'default' = '#d95f02'), guide = F) +
  theme_classic() +
  theme(legend.position="bottom")+
  xlab("Calendar date") + ylab('Value')
```

## Spatial simulations

3-PG is a cohort level model. Thus, to make a simulation across a landscapes we need to explicitly simulate each individual grid point. For this purpose, we will simulate  the *Picea abies* stand biomass across distribution in Switzerland on a 1x1 km grid. In total it summed to ~18’000 grid points over Switzerland. We have prepared the input data, including climate and soil information for each of the grid point. We used interpolated meteorological data done by the Landscape Dynamics group (WSL, Switzerland) using data from MeteoSwiss stations (Swiss Federal Office of Meteorology and Climatology) by employing the DAYMET method (Thornton, Running, & White, 1997). Grid-specific information on soil type and plant available soil water was retrieved from European Soil Database Derived data (Hiederer 2013). In addition, we use ~500 samples drawn from the previously obtained mcmc object and run model simulations for each of the parameter combinations to understand simulation uncertainties. 

We construct a function, which requires site and climate information as input, and calculate $5^{th}$, $50^{th}$ and $95^{th}$ percentile from ~500 simulated runs. To do so, we use the `multidplyr` package for distributing computing. In total, it takes less than 1 hour on a computer cluster with 50 processes (CPU time ~20 hours). 
```{r grid_sim, eval=F}
sim_r3PG_draw <- function(site, forc){
  #' @description simulate the n runs for a given site with the drawn parameters combination
  
  r_3pg_int <- function( p ){
    #' @description function to run one site and return reguired output on standing biomass
    #' @param p a vector of parameters
    # p = param.draw$pars[[1]]
    
    par_def[which( names(par_def) %in% names(p))] = p
    
    out <- f_3PG(site, species.grid, forc, thinn.grid, par_def, matrix(NA_real_,nrow =47,ncol= 1),
      1L, nrow(forc), 1L, 0L, c(1L,1L,1L,0L,0L), 'piab', df_out = F)$sim[,,4,1]
    
    return( last( out ) )
  }
  
  site_out <- param.draw %>%
    mutate( sim = map( pars, r_3pg_int)) %>%
    select(mcmc_id, sim) %>%
    unnest_legacy() %>%
    summarise(
      q05 = quantile(sim, 0.05, na.rm = T),
      q95 = quantile(sim, 0.95, na.rm = T),
      value = quantile(sim, 0.5, na.rm = T))
  
  return( site_out )
}

cl_in <- create_cluster() %>%
  cluster_library(c('r3PG', 'purrr', 'dplyr', 'tidyr')) %>%
  cluster_copy( sim_r3PG_draw ) %>%
  cluster_copy( species.grid ) %>%
  cluster_copy( thinn.grid ) %>%
  cluster_copy( param.draw ) %>%
  cluster_copy( par_def)

#' `hide the sample_n`
sim.grid <- inner_join(site.grid, climate.grid, by = 'grid_id')  %>%
  partition(grid_id, cluster = cl_in) %>%
  mutate( out = map2(site, forc, ~sim_r3PG_draw(.x, .y))) %>%
  select( grid_id, out) %>%
  collect() %>%
  unnest_legacy() %>%
  ungroup()
```
```{r grid_load, include=F}
load('vignette_data/grid_sim.rda')
```

Once the simulations are done, we visualize the results for average standing biomass and associated uncertainties for the whole landscape.
```{r grid_vis, fig.height=3.5, fig.width=6.6}
sim.grid %>%
  mutate( range = q95 - q05) %>%
  select( grid_id, mean = value, range) %>%
  gather( variable, value, -grid_id) %>%
  inner_join( ., coord.grid, by = 'grid_id') %>%
  ggplot( aes(x, y, fill = value) ) +
  geom_raster()+
  facet_wrap(~variable)+
  theme_void()+
  coord_equal() +
  scale_fill_distiller( '', palette = 'Spectral', limits = c(0, 600))
```


## References

* Forrester, D. I., Tachauer, I. H. H., Annighoefer, P., Barbeito, I., Pretzsch, H., Ruiz-Peinado, R., … Sileshi, G. W. (2017). Generalized biomass and leaf area allometric equations for European tree species incorporating stand structure, tree age and climate. Forest Ecology and Management, 396, 160–175. https://doi.org/10.1016/j.foreco.2017.04.011

* Forrester, David I., & Tang, X. (2016). Analysing the spatial and temporal dynamics of species interactions in mixed-species forests and the effects of stand density using the 3-PG model. Ecological Modelling, 319, 233–254. https://doi.org/10.1016/j.ecolmodel.2015.07.010

* Hiederer, R. 2013. Mapping Soil Properties for Europe - Spatial Representation of Soil Database Attributes. Luxembourg: Publications Office of the European Union – 2013 – 47pp. – EUR26082EN Scientific and Technical Research series, ISSN 1831-9424, https://doi.org/10.2788/94128

* Reyer, C. P. O., Silveyra Gonzalez, R., Dolos, K., Hartig, F., Hauf, Y., Noack, M., … Frieler, K. (2019). The PROFOUND database for evaluating vegetation models and simulating climate impacts on forests. Earth System Science Data Discussions, 1–47. https://doi.org/10.5194/essd-2019-220

* Thornton, P. E., Running, S. W., & White, M. A. (1997). Generating surfaces of daily meteorological variables over large regions of complex terrain. Journal of Hydrology, 190(3), 214–251. https://doi.org/10.1016/S0022-1694(96)03128-9
